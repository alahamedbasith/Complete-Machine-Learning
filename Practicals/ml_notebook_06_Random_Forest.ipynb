{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d477d49",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Random Forest uses **bagging** (Bootstrap Aggregating) as its core ensemble method.\n",
    "\n",
    "### Bagging (Bootstrap Aggregating)\n",
    "\n",
    "- **Definition**: Bagging involves training multiple models independently on different random subsets of the training data and then combining their predictions. The subsets are created using bootstrapping, which means sampling with replacement.\n",
    "  \n",
    "- **How It Works in Random Forest**:\n",
    "  - **Bootstrapped Datasets**: For each decision tree in the Random Forest, a bootstrapped dataset is created by randomly sampling the original dataset with replacement. This means each tree is trained on a different random subset of the data, allowing for diversity among the trees.\n",
    "  - **Independent Training**: Each decision tree is trained independently on its respective bootstrapped dataset.\n",
    "  - **Aggregation**: After training, the predictions from all the trees are combined. For classification, this is typically done by majority voting, and for regression, by averaging the predictions.\n",
    "\n",
    "- **Purpose**: The main goal of bagging is to reduce variance and improve the model's generalization by averaging out the predictions from multiple independent models. This leads to a more stable and robust model compared to a single decision tree, which might overfit to the training data.\n",
    "\n",
    "### Boosting\n",
    "\n",
    "Boosting is another ensemble technique, but it is different from bagging. Boosting builds models sequentially, with each new model attempting to correct the errors of the previous ones.\n",
    "\n",
    "- **Sequential Process**: In boosting, models are trained one after the other, with each model trying to improve the performance of the ensemble by focusing on the errors made by previous models. This often involves reweighting the data or adjusting the importance of misclassified examples.\n",
    "- **Adaptive Weights**: Boosting assigns more weight to the data points that were misclassified by previous models, so the new models focus more on these hard-to-classify examples.\n",
    "\n",
    "**Popular Boosting Algorithms**:\n",
    "- **AdaBoost** (Adaptive Boosting)\n",
    "- **Gradient Boosting Machines** (GBM)\n",
    "- **XGBoost** (Extreme Gradient Boosting)\n",
    "- **LightGBM** (Light Gradient Boosting Machine)\n",
    "- **CatBoost** (Categorical Boosting)\n",
    "\n",
    "### Key Differences Between Bagging (Random Forest) and Boosting\n",
    "\n",
    "1. **Training Approach**:\n",
    "   - **Bagging**: Trains multiple models independently on different random subsets of data.\n",
    "   - **Boosting**: Trains models sequentially, with each model focusing on the errors of the previous ones.\n",
    "\n",
    "2. **Aggregation**:\n",
    "   - **Bagging**: Combines predictions by majority vote (classification) or averaging (regression).\n",
    "   - **Boosting**: Combines predictions by giving more weight to models that perform better.\n",
    "\n",
    "3. **Error Reduction**:\n",
    "   - **Bagging**: Aims to reduce variance by averaging multiple independent models.\n",
    "   - **Boosting**: Aims to reduce bias by iteratively focusing on errors and refining the model.\n",
    "\n",
    "In summary, **Random Forest** uses **bagging** to create an ensemble of decision trees, whereas **boosting** is a different technique that sequentially builds models to correct the errors of previous ones.\n",
    "## How Random Forest Works?\n",
    "Random Forest is an ensemble learning method used for both classification and regression tasks. It builds multiple decision trees during training and outputs either the mode of the classes (for classification) or the mean prediction (for regression) of the individual trees.\n",
    "\n",
    "Here's a step-by-step explanation of how Random Forest works:\n",
    "\n",
    "### 1. **Data Preparation**\n",
    "- **Original Dataset**: Let's assume you have a dataset with features \\(X\\) and corresponding labels \\(y\\).\n",
    "  \n",
    "### 2. **Bootstrapping (Sampling with Replacement)**\n",
    "- **Creating Multiple Datasets**:\n",
    "  - From the original dataset, Random Forest creates multiple subsets by randomly sampling with replacement. This process is called **bootstrapping**.\n",
    "  - Each of these subsets will be used to train a separate decision tree.\n",
    "  - Because of the sampling with replacement, some data points might appear multiple times in a subset, while others might not appear at all.\n",
    "\n",
    "### 3. **Growing the Decision Trees**\n",
    "- **Training on Bootstrapped Data**:\n",
    "  - Each decision tree in the Random Forest is trained on a different bootstrapped dataset.\n",
    "  - While growing each tree, Random Forest adds an extra layer of randomness. At each split in the tree, instead of considering all features for the best split, it selects a random subset of features. This ensures that the trees are diverse and not highly correlated.\n",
    "\n",
    "### 4. **Voting/Averaging Predictions**\n",
    "- **Classification**:\n",
    "  - Once all trees are trained, the Random Forest makes predictions by aggregating the predictions of all individual trees.\n",
    "  - For a classification task, each tree casts a \"vote\" for a class. The final prediction is the class that gets the majority of votes (i.e., the mode).\n",
    "  \n",
    "![Random Forest Classification](https://scikit-learn.org/stable/_images/ensemble.png)\n",
    "\n",
    "- **Regression**:\n",
    "  - For a regression task, each tree provides a numerical prediction. The final prediction is the average of all the predictions from the trees.\n",
    "\n",
    "### 5. **Out-of-Bag (OOB) Error (Optional)**\n",
    "- **Internal Validation**:\n",
    "  - Since each tree is trained on a bootstrapped sample, about one-third of the data is left out of each sample. This left-out data is called \"Out-of-Bag\" data.\n",
    "  - The model can evaluate its performance on this OOB data without needing a separate validation set.\n",
    "  - The average error on the OOB samples provides an estimate of the model's performance.\n",
    "\n",
    "### 6. **Final Model**\n",
    "- The Random Forest model combines the predictions of all the individual trees to make its final prediction, either by majority vote (classification) or averaging (regression).\n",
    "\n",
    "### Key Features of Random Forest:\n",
    "\n",
    "1. **Ensemble of Decision Trees**:\n",
    "   - Random Forest is a collection of decision trees. Each tree is trained on a different subset of data and features, which helps in reducing overfitting and improving generalization.\n",
    "\n",
    "2. **Randomness**:\n",
    "   - Two sources of randomness:\n",
    "     1. Bootstrapped sampling of the data.\n",
    "     2. Random feature selection at each split in the tree.\n",
    "   - This randomness makes the trees less correlated and the overall model more robust.\n",
    "\n",
    "3. **Bias-Variance Tradeoff**:\n",
    "   - The individual trees might have high variance (overfit) but low bias. By averaging or voting across many trees, Random Forest reduces the variance without increasing the bias, leading to a model that generalizes well to unseen data.\n",
    "\n",
    "4. **Robust to Overfitting**:\n",
    "   - While individual trees might overfit to their respective datasets, the ensemble of trees tends to generalize well, making Random Forests robust to overfitting compared to a single decision tree.\n",
    "\n",
    "5. **Feature Importance**:\n",
    "   - Random Forest provides insights into which features are most important for predictions. This can be useful for feature selection and understanding the model's decisions.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Training**: Random Forest trains multiple decision trees using bootstrapped datasets and random feature subsets.\n",
    "- **Prediction**: For classification, it uses majority voting among trees; for regression, it averages their predictions.\n",
    "- **Advantages**: High accuracy, robust to overfitting, provides feature importance, works well with large datasets and high dimensionality.\n",
    "- **Disadvantages**: Can be computationally intensive and less interpretable than a single decision tree.\n",
    "\n",
    "Overall, Random Forest is a powerful and versatile machine learning algorithm that is widely used in practice due to its effectiveness and ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39119139",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957c695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "data = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# For classification: let's predict 'survived'\n",
    "# For regression: let's predict 'fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4217a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "1           1       1  female  38.0      1      0  71.2833        C  First   \n",
       "3           1       1  female  35.0      1      0  53.1000        S  First   \n",
       "6           0       1    male  54.0      0      0  51.8625        S  First   \n",
       "10          1       3  female   4.0      1      1  16.7000        S  Third   \n",
       "11          1       1  female  58.0      0      0  26.5500        S  First   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...    ...   \n",
       "871         1       1  female  47.0      1      1  52.5542        S  First   \n",
       "872         0       1    male  33.0      0      0   5.0000        S  First   \n",
       "879         1       1  female  56.0      0      1  83.1583        C  First   \n",
       "887         1       1  female  19.0      0      0  30.0000        S  First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C  First   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "6      man        True    E  Southampton    no   True  \n",
       "10   child       False    G  Southampton   yes  False  \n",
       "11   woman       False    C  Southampton   yes   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "871  woman       False    D  Southampton   yes  False  \n",
       "872    man        True    B  Southampton    no   True  \n",
       "879  woman       False    C    Cherbourg   yes  False  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "\n",
       "[182 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8647c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the Data\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01dbaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>who_woman</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>alive_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare  adult_male  alone  \\\n",
       "1           1       1  38.0      1      0  71.2833       False  False   \n",
       "3           1       1  35.0      1      0  53.1000       False  False   \n",
       "6           0       1  54.0      0      0  51.8625        True   True   \n",
       "10          1       3   4.0      1      1  16.7000       False  False   \n",
       "11          1       1  58.0      0      0  26.5500       False   True   \n",
       "..        ...     ...   ...    ...    ...      ...         ...    ...   \n",
       "871         1       1  47.0      1      1  52.5542       False  False   \n",
       "872         0       1  33.0      0      0   5.0000        True   True   \n",
       "879         1       1  56.0      0      1  83.1583       False  False   \n",
       "887         1       1  19.0      0      0  30.0000       False   True   \n",
       "889         1       1  26.0      0      0  30.0000        True   True   \n",
       "\n",
       "     sex_male  embarked_Q  ...  who_woman  deck_B  deck_C  deck_D  deck_E  \\\n",
       "1       False       False  ...       True   False    True   False   False   \n",
       "3       False       False  ...       True   False    True   False   False   \n",
       "6        True       False  ...      False   False   False   False    True   \n",
       "10      False       False  ...      False   False   False   False   False   \n",
       "11      False       False  ...       True   False    True   False   False   \n",
       "..        ...         ...  ...        ...     ...     ...     ...     ...   \n",
       "871     False       False  ...       True   False   False    True   False   \n",
       "872      True       False  ...      False    True   False   False   False   \n",
       "879     False       False  ...       True   False    True   False   False   \n",
       "887     False       False  ...       True    True   False   False   False   \n",
       "889      True       False  ...      False   False    True   False   False   \n",
       "\n",
       "     deck_F  deck_G  embark_town_Queenstown  embark_town_Southampton  \\\n",
       "1     False   False                   False                    False   \n",
       "3     False   False                   False                     True   \n",
       "6     False   False                   False                     True   \n",
       "10    False    True                   False                     True   \n",
       "11    False   False                   False                     True   \n",
       "..      ...     ...                     ...                      ...   \n",
       "871   False   False                   False                     True   \n",
       "872   False   False                   False                     True   \n",
       "879   False   False                   False                    False   \n",
       "887   False   False                   False                     True   \n",
       "889   False   False                   False                    False   \n",
       "\n",
       "     alive_yes  \n",
       "1         True  \n",
       "3         True  \n",
       "6        False  \n",
       "10        True  \n",
       "11        True  \n",
       "..         ...  \n",
       "871       True  \n",
       "872      False  \n",
       "879       True  \n",
       "887       True  \n",
       "889       True  \n",
       "\n",
       "[182 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54d1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target for regression (predicting fare)\n",
    "X_reg = data.drop('fare', axis=1)\n",
    "y_reg = data['fare']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d11ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for Random Forest Regressor\n",
    "param_grid_reg = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4521e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for Random Forest Regressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search_reg = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                               param_grid=param_grid_reg,\n",
    "                               cv=5,  # 5-fold cross-validation\n",
    "                               n_jobs=-1,  # Use all available cores\n",
    "                               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b34219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search for the regressor\n",
    "grid_search_reg.fit(X_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d356fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_regressor = grid_search_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "845eeff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Regression Mean Squared Error: 1943.05\n",
      "Best Parameters for Regressor: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Best Random Forest Regressor\n",
    "y_pred_reg = best_rf_regressor.predict(X_test_reg)\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "print(f'Best Random Forest Regression Mean Squared Error: {mse:.2f}')\n",
    "print(f'Best Parameters for Regressor: {grid_search_reg.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c346d2d",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101222af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "data = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# For classification: let's predict 'survived'\n",
    "# For regression: let's predict 'fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c62a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Features and target for classification (predicting survival)\n",
    "X_class = data.drop('survived', axis=1)\n",
    "y_class = data['survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb72e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier with some parameters\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10,min_samples_split=2,min_samples_leaf=4,bootstrap=True)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_class = rf_classifier.predict(X_test_class)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f'Classification Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cf10a",
   "metadata": {},
   "source": [
    "Use Hyperparameter tuning for this classifier is our wish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae6027",
   "metadata": {},
   "source": [
    "### Verbose\n",
    "\n",
    "- **`verbose`** is a parameter used in many machine learning libraries, including `GridSearchCV`, to control the level of output printed to the console during the execution of an operation.\n",
    "  \n",
    "- **Functionality**:\n",
    "  - If `verbose=0`: No output is printed. The process runs silently.\n",
    "  - If `verbose=1`: Some basic information is printed. For example, when using `GridSearchCV`, it might print progress on the number of iterations completed.\n",
    "  - If `verbose=2` or higher: More detailed information is printed. This might include more granular updates, such as details about each fold of cross-validation in `GridSearchCV`.\n",
    "\n",
    "- **Purpose**: The main purpose of `verbose` is to help monitor the progress of long-running operations. For example, if you're performing a grid search over many parameter combinations, setting `verbose` to a higher value will give you insight into how far along the process is, which can be especially useful when working with large datasets or complex models.\n",
    "\n",
    "### Bootstrap\n",
    "\n",
    "- **`bootstrap`** is a parameter used in ensemble methods like Random Forests, which determines whether or not bootstrapping is used to create the subsets of data on which each tree in the forest is trained.\n",
    "\n",
    "- **Functionality**:\n",
    "  - If `bootstrap=True`: Bootstrapping is enabled, meaning each tree in the Random Forest is trained on a randomly sampled subset of the data with replacement. This means that some samples might appear multiple times in a subset, while others might not appear at all.\n",
    "  - If `bootstrap=False`: Bootstrapping is disabled, meaning each tree is trained on the entire dataset (or the subset of the data without replacement if a subset is specified).\n",
    "\n",
    "- **Purpose**:\n",
    "  - Bootstrapping helps in creating diverse trees in the forest. Since each tree is trained on a different subset of data, the trees become more varied, reducing the correlation between them. This increases the overall robustness and generalization ability of the Random Forest model.\n",
    "  - Using `bootstrap=True` is the default setting in Random Forests because it tends to improve the model's ability to generalize to new, unseen data. It also gives the algorithm a sense of \"built-in\" randomness, which helps in preventing overfitting.\n",
    "\n",
    "In summary:\n",
    "- **`verbose`** controls the amount of information output during an operation.\n",
    "- **`bootstrap`** determines whether each tree in a Random Forest is trained on a random subset of the data (with replacement) or on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef964a",
   "metadata": {},
   "source": [
    "## Deep Dive in Bootstrapping\n",
    "\n",
    "**Bootstrapping** is a statistical method that involves sampling with replacement. In the context of Random Forests, it refers to how the data is used to train each individual tree in the forest.\n",
    "\n",
    "### Example to Understand Bootstrapping\n",
    "\n",
    "Imagine you have a dataset with 5 samples:\n",
    "\n",
    "```\n",
    "Dataset: [A, B, C, D, E]\n",
    "```\n",
    "\n",
    "If we use **bootstrapping** (`bootstrap=True`), here's what happens when training a single tree in the Random Forest:\n",
    "\n",
    "1. **Sampling with Replacement**: \n",
    "   - You randomly select samples from the original dataset, but with replacement. \n",
    "   - This means after selecting a sample, you put it back into the dataset, so it can be chosen again.\n",
    "\n",
    "2. **Example of Bootstrapped Sample**:\n",
    "   - You might end up with a sample like: `[A, C, E, A, B]`\n",
    "   - Notice that `A` appears twice, `D` is missing entirely.\n",
    "\n",
    "3. **Training the Tree**:\n",
    "   - This tree is trained on the bootstrapped sample `[A, C, E, A, B]`.\n",
    "\n",
    "When you build the next tree in the forest, a new bootstrapped sample is created, such as `[B, D, D, E, A]`.\n",
    "\n",
    "### Why Use Bootstrapping?\n",
    "\n",
    "1. **Diversity Among Trees**: \n",
    "   - Each tree in the forest is trained on a different random sample of the data. This introduces diversity among the trees, as they each see slightly different data.\n",
    "\n",
    "2. **Reducing Overfitting**:\n",
    "   - If every tree was trained on the exact same data, they might all make similar mistakes and overfit to the training data. Bootstrapping ensures that trees are more independent of each other, which improves the overall performance of the Random Forest.\n",
    "\n",
    "### What Happens if `bootstrap=False`?\n",
    "\n",
    "- If you set `bootstrap=False`, then each tree is trained on the entire dataset without sampling. All trees see the same data, leading to less diversity among the trees. This might make the Random Forest less robust because the trees are more likely to make the same errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a925a",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "The random forest works with bagging so the classification problem output is based on Majority Voting and regression problem is based on bootstrap aggregating mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224d006",
   "metadata": {},
   "source": [
    "#### Prepared By,\n",
    "Ahamed Basith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75b625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
