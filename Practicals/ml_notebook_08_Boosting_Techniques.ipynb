{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7afc96",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "## Terminologies\n",
    "The terminologies and concepts in boosting is crucial for effectively applying these methods in machine learning. Here’s a breakdown of key terms and concepts related to boosting:\n",
    "\n",
    "### Key Terminologies in Boosting\n",
    "\n",
    "1. **Weak Learner**:\n",
    "   - **Definition**: A weak learner is a model that performs slightly better than random chance. It’s a simple model, like a decision tree with a shallow depth (e.g., a stump), which individually may not have high accuracy but can contribute to the final model when combined.\n",
    "   - **Role in Boosting**: Boosting algorithms iteratively train weak learners to correct the errors of previous learners. By combining many weak learners, boosting creates a strong learner with high predictive power.\n",
    "\n",
    "2. **Strong Learner**:\n",
    "   - **Definition**: A strong learner is a model that performs well and has high accuracy. It is typically an ensemble of weak learners combined to form a more accurate and robust model.\n",
    "   - **Role in Boosting**: The goal of boosting is to create a strong learner by aggregating the predictions of weak learners.\n",
    "\n",
    "3. **Ensemble Learning**:\n",
    "   - **Definition**: Ensemble learning refers to combining multiple models to improve performance and robustness compared to a single model.\n",
    "   - **Role in Boosting**: Boosting is a form of ensemble learning where multiple weak learners are combined to form a strong learner. Each weak learner corrects the errors of its predecessors, leading to improved performance.\n",
    "\n",
    "4. **Boosting**:\n",
    "   - **Definition**: Boosting is an iterative ensemble technique that combines the predictions of several base models (weak learners) to produce a single strong model. Each new model in the sequence focuses on the errors made by the previous models.\n",
    "   - **How it Works**: Boosting adjusts the weights of misclassified instances so that subsequent models focus more on difficult cases, leading to a reduction in bias and variance.\n",
    "\n",
    "5. **Learning Rate**:\n",
    "   - **Definition**: The learning rate (or step size) is a parameter that controls the contribution of each weak learner to the final model. It determines how much the weights of misclassified instances are adjusted.\n",
    "   - **Role in Boosting**: A smaller learning rate requires more weak learners to converge, potentially leading to a more robust model but at the cost of increased computation. A larger learning rate speeds up training but may risk overfitting.\n",
    "\n",
    "6. **Weighted Data**:\n",
    "   - **Definition**: In boosting, instances that are misclassified or have higher errors are given higher weights so that the next model focuses more on them.\n",
    "   - **Role in Boosting**: By re-weighting data, boosting focuses on correcting mistakes made by previous models, leading to improved accuracy.\n",
    "\n",
    "7. **Residuals**:\n",
    "   - **Definition**: Residuals are the differences between the actual values and the predicted values of the model. They represent the errors or discrepancies in predictions.\n",
    "   - **Role in Boosting**: Boosting algorithms aim to reduce the residuals by iteratively training models to correct errors made by previous models.\n",
    "\n",
    "8. **AdaBoost (Adaptive Boosting)**:\n",
    "   - **Definition**: AdaBoost is a specific boosting algorithm that adjusts the weights of instances based on errors. It combines weak learners to improve model performance, focusing more on instances that were misclassified by previous models.\n",
    "   - **Key Feature**: AdaBoost assigns higher weights to misclassified instances, making them more influential in the training of subsequent weak learners.\n",
    "\n",
    "9. **Gradient Boosting**:\n",
    "   - **Definition**: Gradient Boosting is another boosting algorithm that builds models in a stage-wise manner and optimizes a loss function using gradient descent.\n",
    "   - **Key Feature**: Each new model is trained to minimize the residual errors of the combined ensemble, resulting in better performance over iterative stages.\n",
    "\n",
    "10. **XGBoost (Extreme Gradient Boosting)**:\n",
    "    - **Definition**: XGBoost is an optimized implementation of gradient boosting that includes regularization to prevent overfitting, efficient handling of missing values, and parallel processing.\n",
    "    - **Key Feature**: XGBoost often achieves high performance and efficiency due to its advanced optimization techniques and additional features.\n",
    "\n",
    "### Why Boosting?\n",
    "\n",
    "Boosting is widely used because it offers several advantages:\n",
    "\n",
    "1. **Improved Accuracy**:\n",
    "   - Boosting combines multiple weak learners to create a strong learner with high accuracy, often outperforming individual models.\n",
    "\n",
    "2. **Bias-Variance Tradeoff**:\n",
    "   - Boosting reduces bias by combining weak learners and can also help manage variance by focusing on misclassified instances and correcting errors.\n",
    "\n",
    "3. **Flexibility**:\n",
    "   - Boosting can be applied to various types of models and can handle different types of data, making it versatile for various tasks.\n",
    "\n",
    "4. **Robustness**:\n",
    "   - By iteratively correcting errors, boosting can create robust models that perform well on unseen data.\n",
    "\n",
    "5. **Feature Importance**:\n",
    "   - Boosting algorithms can provide insights into feature importance, helping to understand which features are most influential for predictions.\n",
    "\n",
    "Overall, boosting is a powerful technique that enhances model performance by iteratively refining predictions, making it a valuable tool in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece165d8",
   "metadata": {},
   "source": [
    "## Boosting For Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d744be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor, VotingClassifier, VotingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977af0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load iris dataset\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Need to encode species because that is categorical variable\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'species' column\n",
    "iris['species'] = le.fit_transform(iris['species'])\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b4470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = iris.drop('species', axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3e46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bef29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_class = ada_clf.predict(X_test_class)\n",
    "print(\"AdaBoost Classifier Accuracy:\", accuracy_score(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404f4c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_class = gb_clf.predict(X_test_class)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93762422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_class = xgb_clf.predict(X_test_class)\n",
    "print(\"XGBoost Classifier Accuracy:\", accuracy_score(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7e9a2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369dabb5",
   "metadata": {},
   "source": [
    "### For AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32600d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_class, y_train_class)\n",
    "print(\"Best Parameters for AdaBoost:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aae1a",
   "metadata": {},
   "source": [
    "### For Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c80cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_class, y_train_class)\n",
    "print(\"Best Parameters for Gradient Boosting:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff48a05",
   "metadata": {},
   "source": [
    "### For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467c5310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_class, y_train_class)\n",
    "print(\"Best Parameters for XGBoost:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35bf20",
   "metadata": {},
   "source": [
    "## Boosting For Regression Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c46e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor, VotingClassifier, VotingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78e86e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40785b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, use only numerical features and a target variable\n",
    "# Note: The 'price' column is our target variable\n",
    "X = diamonds.select_dtypes(include=[np.number]).drop('price', axis=1).fillna(0)\n",
    "y = diamonds['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f9bfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z\n",
       "0       0.23   61.5   55.0  3.95  3.98  2.43\n",
       "1       0.21   59.8   61.0  3.89  3.84  2.31\n",
       "2       0.23   56.9   65.0  4.05  4.07  2.31\n",
       "3       0.29   62.4   58.0  4.20  4.23  2.63\n",
       "4       0.31   63.3   58.0  4.34  4.35  2.75\n",
       "...      ...    ...    ...   ...   ...   ...\n",
       "53935   0.72   60.8   57.0  5.75  5.76  3.50\n",
       "53936   0.72   63.1   55.0  5.69  5.75  3.61\n",
       "53937   0.70   62.8   60.0  5.66  5.68  3.56\n",
       "53938   0.86   61.0   58.0  6.15  6.12  3.74\n",
       "53939   0.75   62.2   55.0  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80b38fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         326\n",
       "1         326\n",
       "2         327\n",
       "3         334\n",
       "4         335\n",
       "         ... \n",
       "53935    2757\n",
       "53936    2757\n",
       "53937    2757\n",
       "53938    2757\n",
       "53939    2757\n",
       "Name: price, Length: 53940, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "357c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e41061be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regressor MSE: 3829080.421358767\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train AdaBoost Regressor\n",
    "ada_reg = AdaBoostRegressor()\n",
    "ada_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_reg = ada_reg.predict(X_test_reg)\n",
    "print(\"AdaBoost Regressor MSE:\", mean_squared_error(y_test_reg, y_pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4edca1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor MSE: 1807043.3489397182\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Gradient Boosting Regressor\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "gb_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_reg = gb_reg.predict(X_test_reg)\n",
    "print(\"Gradient Boosting Regressor MSE:\", mean_squared_error(y_test_reg, y_pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2733a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor MSE: 1856425.204958547\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train XGBoost Regressor\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_reg = xgb_reg.predict(X_test_reg)\n",
    "print(\"XGBoost Regressor MSE:\", mean_squared_error(y_test_reg, y_pred_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a46cb",
   "metadata": {},
   "source": [
    "The MSE is very very high therefore the model does not perform well.The reason of applying this for understanding.In order to reduce mse,the following things you should consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfbcf3",
   "metadata": {},
   "source": [
    "A Mean Squared Error (MSE) of 1,806,821.48 indicates that the predictions of your Gradient Boosting Regressor model are not performing well. To improve the model, you might consider the following steps:\n",
    "\n",
    "1. **Feature Engineering**: Reevaluate the features you're using. Sometimes, adding new features or transforming existing ones can improve model performance.\n",
    "\n",
    "2. **Hyperparameter Tuning**: Gradient Boosting models have several hyperparameters that can be tuned, such as the number of trees (`n_estimators`), the learning rate (`learning_rate`), and the maximum depth of the trees (`max_depth`). Use techniques like Grid Search or Random Search to find the best combination of these parameters.\n",
    "\n",
    "3. **Model Complexity**: Check if your model is too complex or too simple. Overfitting can occur if the model is too complex, while underfitting can occur if it's too simple. Adjust the model complexity by changing hyperparameters.\n",
    "\n",
    "4. **Cross-Validation**: Use cross-validation to ensure that your model's performance is consistent across different subsets of the data.\n",
    "\n",
    "5. **Data Quality**: Ensure that your data is clean and representative. Outliers, missing values, or noise in the data can negatively impact model performance.\n",
    "\n",
    "6. **Comparison with Other Models**: Compare the performance of Gradient Boosting with other regression models like Random Forest, XGBoost, or even linear models to see if they perform better.\n",
    "\n",
    "7. **Scaling and Normalization**: Ensure that your features are properly scaled and normalized if required by the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb48386",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0ea08",
   "metadata": {},
   "source": [
    "### For AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e41cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for AdaBoost: {'learning_rate': 0.01, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "grid_search = GridSearchCV(AdaBoostRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "print(\"Best Parameters for AdaBoost:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a8df5",
   "metadata": {},
   "source": [
    "### For Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004175b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "print(\"Best Parameters for Gradient Boosting:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872c979",
   "metadata": {},
   "source": [
    "### For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b51caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_reg, y_train_reg)\n",
    "print(\"Best Parameters for XGBoost:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63831446",
   "metadata": {},
   "source": [
    "## Custom Boosting with Multiple Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242b449",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "```python\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('gb', GradientBoostingClassifier()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_class, y_train_class)\n",
    "y_pred_class = voting_clf.predict(X_test_class)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test_class, y_pred_class))\n",
    "```\n",
    "\n",
    "### Regression\n",
    "\n",
    "```python\n",
    "voting_reg = VotingRegressor(estimators=[\n",
    "    ('ada', AdaBoostRegressor()),\n",
    "    ('gb', GradientBoostingRegressor()),\n",
    "    ('xgb', xgb.XGBRegressor())\n",
    "])\n",
    "\n",
    "voting_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = voting_reg.predict(X_test_reg)\n",
    "print(\"Voting Regressor MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d09797",
   "metadata": {},
   "source": [
    "#### Prepared By,\n",
    "Ahamed Basith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a226b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
