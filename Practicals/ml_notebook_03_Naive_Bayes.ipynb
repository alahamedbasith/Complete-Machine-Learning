{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea9341d",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Naive Bayes is a family of probabilistic classifiers based on Bayes' Theorem, which assumes that the features are independent given the class. It's particularly popular for text classification tasks like spam detection, sentiment analysis, etc.\n",
    "\n",
    "### Naive Bayes Overview:\n",
    "1. **Bayes' Theorem**:  \n",
    "   \\[\n",
    "   P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "   \\]\n",
    "   In the context of classification, we use:\n",
    "   \\[\n",
    "   P(C|X) = \\frac{P(X|C) \\cdot P(C)}{P(X)}\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\( P(C|X) \\) is the posterior probability of class \\( C \\) given the feature set \\( X \\).\n",
    "   - \\( P(X|C) \\) is the likelihood of feature set \\( X \\) given the class \\( C \\).\n",
    "   - \\( P(C) \\) is the prior probability of class \\( C \\).\n",
    "   - \\( P(X) \\) is the prior probability of feature set \\( X \\) (can be ignored for classification purposes since it remains constant).\n",
    "\n",
    "2. **Types of Naive Bayes**:\n",
    "   - **Gaussian Naive Bayes**: Assumes that the features follow a normal distribution.\n",
    "   - **Multinomial Naive Bayes**: Used for discrete features like word counts.\n",
    "   - **Bernoulli Naive Bayes**: Used for binary/boolean features.\n",
    "\n",
    "### Explanation:\n",
    "- **Train-test split**: Divides the dataset into training (70%) and testing (30%) sets.\n",
    "- **GaussianNB**: A Naive Bayes classifier assuming Gaussian distribution for the features.\n",
    "- **Accuracy**: The ratio of correct predictions to the total predictions.\n",
    "- **Confusion Matrix**: A table showing the performance of the classifier by displaying true positives, true negatives, false positives, and false negatives.\n",
    "- **Classification Report**: Includes precision, recall, F1-score, and support for each class.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "#### **1. `alpha`**\n",
    "\n",
    "- **What It Does**: Adds a small number to each feature's count to avoid problems with features that don’t appear in the training data.\n",
    "- **Why It's Needed**: Sometimes, a feature might be missing in the training data for a particular class. `alpha` helps ensure that the model doesn’t assume zero probability for these features.\n",
    "- **When to Adjust**: Use `alpha` if you notice that some features are missing in your training data, or if your model is giving zero probabilities for certain features.\n",
    "\n",
    "**Example**: If you’re classifying emails and a word doesn’t appear in your training set, `alpha` helps the model handle that missing word by giving it a small, non-zero count.\n",
    "\n",
    "#### **2. `binarize`**\n",
    "\n",
    "- **What It Does**: Sets a cutoff value to decide if a feature should be considered as \"present\" (1) or \"absent\" (0).\n",
    "- **Why It's Needed**: For binary features (like whether a word is present in an email), this parameter helps convert the feature values into binary format.\n",
    "- **When to Adjust**: Use this if you have features with continuous values and want to convert them to a binary format.\n",
    "\n",
    "**Example**: If you have a feature that measures the frequency of a word and you set `binarize` to 0.5, any frequency above 0.5 will be considered as \"present\" (1), and below it will be considered \"absent\" (0).\n",
    "\n",
    "#### **3. `var_smoothing`**\n",
    "\n",
    "- **What It Does**: Adds a small value to the variance of features to avoid problems with very small or zero variances.\n",
    "- **Why It's Needed**: If some features have very small variance, the model might run into numerical issues. This parameter helps keep calculations stable.\n",
    "- **When to Adjust**: Use this if your model is having trouble with very small or zero variance in the features.\n",
    "\n",
    "**Example**: If you're using a Gaussian Naive Bayes model and some features have almost no variability, `var_smoothing` helps the model handle those features more reliably.\n",
    "\n",
    "#### **4. `fit_prior`**\n",
    "\n",
    "- **What It Does**: Decides whether the model should learn the prior probabilities of different classes from the training data or use equal probabilities for all classes.\n",
    "- **Why It's Needed**: If you want the model to use the actual distribution of classes in your data, set this to `True`. If you prefer all classes to be treated equally, set it to `False`.\n",
    "- **When to Adjust**: Use this if you have a reason to assume that classes should have equal probabilities or if you want the model to learn from the data.\n",
    "\n",
    "**Example**: If you have 90% of class A and 10% of class B in your training data, `fit_prior=True` will make the model consider this imbalance. If set to `False`, the model will assume that both classes are equally likely, regardless of the actual distribution.\n",
    "\n",
    "#### **5. `class_prior`**\n",
    "\n",
    "- **What It Does**: Allows you to specify the probabilities of the classes manually instead of learning them from the data.\n",
    "- **Why It's Needed**: Use this if you have prior knowledge about the class distribution and want the model to use this information instead of learning it from the training data.\n",
    "- **When to Adjust**: Set this if you have strong reasons to believe in specific class probabilities that are different from what your training data shows.\n",
    "\n",
    "**Example**: If you know that in the real world, class A is twice as likely as class B, you can set `class_prior` to reflect this before training your model.\n",
    "\n",
    "In summary, these parameters help adjust how the Naive Bayes model handles feature data, class distributions, and numerical stability to improve accuracy and performance.\n",
    "### Running the Code:\n",
    "- The `load_iris()` function loads a dataset for demonstration purposes.\n",
    "- The output will show the performance of the Naive Bayes classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4176c39",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    " Assumes that the features follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde3df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3a5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset (e.g., iris dataset)\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Labels\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccff319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0f6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce5250",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "- Use Case: Best for discrete features, especially when dealing with word counts or frequencies. It’s commonly used in text classification tasks where features represent the number of times a word appears in a document.\n",
    "- Feature Assumption: Assumes that features are counts of occurrences, such as the number of times a word appears in a document.\n",
    "- Probability Calculation: The probability of a feature given a class is modeled using a multinomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab092cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Sample dataset\n",
    "texts = [\"I love programming\", \"Python is great\", \"I hate bugs\", \"Coding is fun\", \"Debugging is hard\"]\n",
    "labels = [1, 1, 0, 1, 0]  # Example labels: 1 for positive sentiment, 0 for negative sentiment\n",
    "\n",
    "# Convert text data into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a608a48",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes\n",
    "- Use Case: Suitable for binary/boolean features, where each feature represents the presence or absence of a characteristic (e.g., whether a word is present or not in a document).\n",
    "- Feature Assumption: Assumes binary features (0 or 1), like whether a word appears or not in a document.\n",
    "- Probability Calculation: The probability of a feature given a class is modeled using a Bernoulli distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62cb73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Sample dataset\n",
    "texts = [\"I love programming\", \"Python is great\", \"I hate bugs\", \"Coding is fun\", \"Debugging is hard\"]\n",
    "labels = [1, 1, 0, 1, 0]  # Example labels: 1 for positive sentiment, 0 for negative sentiment\n",
    "\n",
    "# Convert text data into feature vectors\n",
    "vectorizer = CountVectorizer(binary=True)  # Binary feature vectors\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "model = BernoulliNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0306a51",
   "metadata": {},
   "source": [
    "#### Prepared By,\n",
    "Ahamed Basith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbef99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
