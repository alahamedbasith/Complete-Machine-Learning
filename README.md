# Complete Machine Learning with End-to-End Deployment

## Lecture - 01
- **Introduction to ML**
- **Difference Between AI, ML, DL, and DS**
- **Types of Machine Learning**
  - Supervised Machine Learning
  - Unsupervised Machine Learning
  - Reinforcement Learning
- **Regression and Classification Problems**
- **Important Algorithms for ML**
- **Linear Regression and Mathematical Intuition**
- **Cost Function of Linear Regression**
- **Global Minima and Local Minima**
- **Gradient Descent and Convergence Algorithm**
- **Performance Metrics of Regression Problem**
  - R Square
  - Adjusted R Square
  - MSE

## Lecture - 02
- **Multiple and Polynomial Regression**
- **Ridge and Lasso Regressor with Math Intuition**
- **Elastic Net Regressor**
- **Variance Inflation Factor and Multicollinearity**
- **Convex and Non-Convex Functions**
- **Logistic Regression with Math Intuition**
- **Decision Boundary of Logistic Regression for Binary Classification**
- **Decision Boundary of Logistic Regression for Multi-Class Classification**
- **Confusion Matrix and Classification Reports**
- **Balanced and Imbalanced Datasets**
- **Performance Metrics for Classification Problems**
  - Precision
  - Recall
  - F-Score

## Lecture - 03
- **Implementation of Linear Models**
- **Naive Bayes with Mathematical Intuition**
  - Gaussian Naive Bayes
  - Multinomial Naive Bayes
  - Bernoulli Naive Bayes
- **Cross Validation and Its Types**
- **Hyperparameter Tuning and Its Types**
- **Strong and Weak Regularization**
- **Implementation of Naive Bayes**
- **KNN with Mathematical Intuition**
  - KNN Classifiers
  - KNN Regressors
- **Euclidean Distance and Manhattan Distance**

## Lecture - 04
- **Decision Tree with Mathematical Intuition**
- **Decision Tree Classifiers and Regressors**
- **Pure Split and Impure Split**
- **Entropy and Gini Impurity**
- **Information Gain with Math Intuition**
- **Post and Pre-Pruning in Decision Tree**
- **Important Parameters Used in Decision Tree**
- **Decision Tree Visualization**

## Lecture - 05
- **Introduction to Ensemble Techniques**
- **Bagging and Boosting**
- **Random Forest with Mathematical Intuition**
  - Random Forest Classifiers
  - Random Forest Regressors
- **Majority Voting and Bootstrap Aggregating**
- **Strong Learners and Weak Learners**
- **Bagging Classifiers and Bagging Regressors**
- **Custom Bagging with Multiple Algorithms**
- **Types of Boosting Algorithms**
  - AdaBoost with Math Intuition
  - XGBoost with Math Intuition
  - Gradient Boost with Math Intuition
- **Regressors and Classifiers for AdaBoost, XGBoost, and Gradient Boost**
- **Custom Boosting with Multiple Algorithms**
- **Black Box and White Box Models**

## Lecture - 06
- **Discussing K-Means Clustering**
  - Centroids and Groups
  - Elbow Method for K-Means Clustering
  - WCSS and BCSS
  - Purpose of K-Means++
- **Hierarchical Clustering and Dendogram**
- **Validating Clustering Models Using Silhouette Score**
- **DBSCAN Clustering and Its Parameters**
  - DBSCAN Clustering and Outliers Detection
  - Why Silhouette Score is Not Used in DBSCAN Clustering
- **Support Vector Machine (SVM) with Mathematical Intuition**
  - SVM Classifiers and Regressors
  - SVM Hyperplane, Soft, and Hard Margin
  - SVM Kernels and Its Types (Linear, Polynomial, RBF)
- **PCA and LDA** (Already Uploaded in Data Mining (Feature Selection Course))

## Projects
Projects are available in the projects folder in the repository.

## Requirements

- **Strong in Python and Data Science Libraries**
- **Strong in Descriptive and Inferential Statistics**
- **Strong in Data Mining with Respect to Feature Engineering and Feature Selection**
- **Basics in Calculus and Algebra** (12th Grade Math is Enough)

